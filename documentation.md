## Documentation 2016-01-23

The purpose of this document is to communicate functional content of the program, as well as create roadmap for future development. It lives in the github repo and in the shared Dropbox of the program project. Intended audience includes developers Colin Henry and Christopher Butler, as well as other project partners. Note that cited code is often incomplete, in development, or contains excessive comments.

### score_set_pipeline.py

The score-set pipeline is an implementation of the NSF pilot project. It implements a `Score Set` object that contains values for `country`, `year`, `score`, and `text`. The `Score Set` object represents a single observation at the country-year-report level, where `score` is any human- or machine-generated SV score and `text` is any text-based feature extraction. This means that `text` can contain any potential feature, including a `string` of the entire report text, a `list` of sentences, or a `list` of keywords. 

The `Score Set` object:

```python
class Score_Set(object) : 
	def __init__(self,score,text,country,year) : 
		self.country = country
		self.year = year
		self.score = score
		self.text = text
```

The project accepts a sinle user input, `train_dir`, which indicates the directory containing both the corpus of reports and the human-coded training data. It also includes nine seperate functions.

#### import_text

`import_text` imports the corpus of reports and the human coded training data. It accepts a single input, `file_dir`, expected to be a string corresponding to the user input `train_dir`. 

```python
def import_text(file_dir) : 
	for root,dirs,files in os.walk(file_dir) : 
```

The above `for` loop iterates over the file directory. Thus, reports and coding documents can be nested inside additional folders without problem.


```python
		# Filter file lists by file type
		reports = [ fi for fi in files if fi.endswith(".txt") ]
		key_file = [ fi for fi in files if fi.endswith(".xls") ]
```

The corpus of human rights reports are expected to be in plaintext format (preferably in UTF-8 encoding), and to be the only plaintext formatted documents in the directory. Similarly, the coding document ought to be in Excel format, and the only Excel formatted document in the directory. 
> Future development: the reliance on Excel formatted coding documents is a weakness for the unversalization of the pipeline project. Users ought to be able to specify the document format, structure, and content with some flexibility. Obviously there should be some expectation that the data follows a reasonable formatting pattern, but we ought to accept inputs from Stata, plaintext, csv, etc. -- common file formats used by social scientists.

The following break-down of the digestion of the corpus and coding documents will illustrate why strictly constraining the input format was necessary for the baseline pilot project.

```python		
		# Create empty Numpy array with file list length
		train_set = [] * len(reports)
		train_set2 = [] * len(reports)
		# print train_set
		# index = 0 
		for fname in reports : 
			path = os.path.join(root,fname)
			with open(path) as infile : 
				raw_text = unicode(infile.read(),encoding='utf-8',errors='ignore')
			fname_split = fname.split('_')
			# print fname_split
			tmp = Score_Set(None,raw_text,fname_split[0],fname_split[1])
			# print tmp.country
			train_set.append(tmp)
			# print fname
			# index = index + 1
		# train_set.pop(0)
		# train_np = np.array(train_set)
		# print train_np
```

After generating a file list from the directory input, the above `for` loop iterates over the list, opening each file and reading the raw text into a temporary `Score Set` object. The object takes the raw text, the country name portion of the filename, and the year portion of the filename as input. The text score is set to `None`, which allows for future scoring of the report. The temporary `Score Set` object is appended to the training set Numpy array.

```python
		for fname in key_file : 
			path = os.path.join(root,fname)
			workbook = xlrd.open_workbook(path, on_demand = True)
			worksheet = workbook.sheet_by_index(0)
			for row in range(0, worksheet.nrows) : 
				if row == 0 : 
					continue
				else : 
					tmp = Score_Set(None,None,None,None)
					for col in range(0, worksheet.ncols) : 
						if col == 0 : 
							continue
						elif col == 1 : 
							tmp.year = worksheet.cell(row,col).value
						elif col == 2 : 
							tmp.country = worksheet.cell(row,col).value
						elif col == 3 : 
							continue
						elif col == 4 : 
							tmp.score = worksheet.cell(row,col).value
						else : 
							continue
					train_set2.append(tmp)
```

Using the `xlrd` package, the next `for` loop opens the coding document and extracts scores for each corpus document. Processing the coding document is hard-coded for the expected format. The expected format is simply the format of the initial coding document generated by human-coders for the Butler-Jones publication. The first row is a header of variable names, and is ignored; the first column is also identifying information and ignored. Columns 1, 2, and 4 are added to the temporary `Score Set` object as year, country, and score values, respectively. The temporary object is then appended to a temporary Numpy array.
> Future development: For speed and efficacy in the pilot project, the structure of the coding document was hard-coded into the function. Any future iteration of this module should be greatly expanded to allow for numerous data structures and formats. Moreover, it should accept user input -- that is, users should be able to specify arbitrary input formats at will.

```python
	for t in train_set : 
		for t2 in train_set2 : 
			if float(t.year) == float(t2.year) and t.country == t2.country :
				# print "y"
				t.score = str(t2.score)
	# print [s.score for s in train_set]
	# print len(train_set)
	return train_set
	# Combining stuff
	# dictionary = {attr1, attr2 : }
```

Finally, the two Numpy arrays of `Score Set` objects are compared by year and country; identical observations in the corpus training set are modified with the human-coded score. The new, completed training set is returned from the function.
> Future development: Numpy arrays are necessary for the actual classification pipeline, but have a comparatively large memory footprint. Using multiple Numpy arrays to arrive at a final training set is clearly not the most efficient method of reading the corpus and human-coded data. Using some fairly typical memory optimization strategies, we should be able to rewrite this portion to operate much faster.

#### split_corpus

```python
def split_corpus(train_set) :
	corpus = []
	training = []
	for t in train_set : 
		if t.score is not None : 
			training.append(t)
		else : 
			corpus.append(t)
	# print len(corpus)
	# print len(training)
	return corpus, training
```

This function simply splits the score-complete corpus based on the value of the `score` parameter.
> Future development: Obviously, this function is redundant and/or far too specific to be of use in a final pipeline. It should either be integrated into the `import_text` function (e.g., returning both the scored and unscored arrays separately) or generalized for internal use.

#### import_corpus

```python
def import_corpus(corpus_dir) : 
	corpus = sklearn.datasets.load_files(corpus_dir)
	return corpus
```
This function is deprecated or redundant.

#### feature_text

```python
def feature_text(train_set) :
	# Extract counts
	# print train_set
	count_vect = CountVectorizer()
	train_counts = count_vect.fit_transform([s.text for s in train_set])
```

The `feature_text` function is the crucial feature extraction step in the pipeline. Given a training set as a Numpy array of `Score Set` objects, it first extracts term frequencies from the entire training set. It uses the `CountVectorizer` function from the `sklearn.feature_extraction.text` package, a general purpose term counter included in `scikit-learn`. First, a `CountVectorizer` object is instantiated, and then the `fit_transform` function is called. This function takes an array of strings as input; in this case, an iterable function of each `text` parameter from each `Score Set` object in the training set Numpy array. The function returns an array of counts in vector format for each member of the array.

```python
	# print train_counts
	# Extract term frequencies
	# tf_transformer = TfidfTransformer(use_idf=False).fit(train_counts)
	# train_tf = tf_transformer.transform(train_counts)
	# Extract term frequency times inverse document frequency
	tfidf_transformer = TfidfTransformer()
	train_tfidf = tfidf_transformer.fit_transform(train_counts)

	# tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')
	# train_vector = tfidf_vectorizer.fit_transform([s.text for s in train_set])

	# sample_counts = count_vect.transform([s.text for s in sample_set])
	# sample_tfidf = tfidf_transformer.transform(sample_counts)
	# sample_vector = tfidf_vectorizer.fit_transform([s.text for s in sample_set])
	# sample_tf = tf_transformer.transform(sample_counts)
	# print train_tfidf
	return train_tfidf
```

Second, a `TfidfTransformer` object is instantiated from the same `sklearn` package. This object transforms the count vectors into the term frequency times inverse document frequency count, a measure that discounts the frequency of terms by the use across all documents in the corpus, reducing the impact on the feature set of common words, such as articles or stop words. The `feature_text` function then returns the array of TFIDF counts in vector format. This represents the feature set of the corpus.

#### test_text

```python
def test_text(sample_set) :
	# Extract counts
	# print train_set
	count_vect = CountVectorizer()
	sample_counts = count_vect.transform([s.text for s in sample_set])
	# print train_counts
	# Extract term frequencies
	# tf_transformer = TfidfTransformer(use_idf=False).fit(train_counts)
	# train_tf = tf_transformer.transform(train_counts)
	# Extract term frequency times inverse document frequency
	tfidf_transformer = TfidfTransformer()
	sample_tfidf = tfidf_transformer.transform(sample_counts)
	# print train_tfidf
	return sample_tfidf
```

This function is deprecated or redundant.

#### train_text

```python
def train_text(sample_set, train_tfidf) : 
	# Train classifier
	sample_set = [s.score for s in sample_set]
	sample_set = label_binarize(sample_set, classes=[0, 1, 2, 3, 4])
	# BINARIZE HERE
	# print sample_set
	# print sample_set.shape
	# print train_tfidf.shape
	# classifier = MultinomialNB().fit(train_tfidf, sample_set)
	classifier = multiclass.OneVsRestClassifier(svm.SVC(kernel='linear',probability=True)).fit(train_tfidf, sample_set)
	# RETRAIN WITH OnevsRest classifier -- MULTILABEL -- SEE bookmarks
	# classifier = MultinomialNB(fit_prior=True).fit(train_tfidf, [s.score for s in sample_set])
	print classifier
	predicted = classifier.predict(train_tfidf)
	# x = [s.score for s in sample_set]
	# print x
	# np.set_printoptions(threshold=np.inf)
	# print x
	# print np.mean(predicted == x)
	return classifier
```
